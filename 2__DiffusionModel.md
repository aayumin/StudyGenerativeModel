# 🌫️ Diffusion Model
---

## 📚 목차

1. Diffusion Model이란?
2. Diffusion Model을 이해하기 위한 선수 지식
   - 2.1 확률분포와 샘플링
   - 2.2 노이즈의 개념
   - 2.3 마르코프 과정(Markov Process)
3. Diffusion Model의 핵심 개념
   - 3.1 Forward Process (Diffusion)
   - 3.2 Reverse Process (Denoising)
   - 3.3 Noise Schedule 
   - 3.4 Noise Function 
4. 학습 방식
   - 4.1 목표: 노이즈 예측
   - 4.2 Loss Function (MSE 기반)
5. 샘플 생성 방법
6. 주요 모델 (DDPM, Stable Diffusion 등)
7. Diffusion Model의 장점과 한계

---

## 1. Diffusion Model이란?

Diffusion Model은 **랜덤한 노이즈에서 시작해 점차 이미지를 복원하는 방식**으로 작동하는 생성모델입니다.

이미지를 점점 망가뜨렸다가,  
그 반대 과정을 따라가며 다시 그려내는 것입니다.

> 🎨 **비유**: 퍼즐 그림을 일부러 흐릿하게 만들고,  
> 다시 원래 상태로 복원하는 마법을 배우는 것과 비슷합니다.

---

## 2. Diffusion Model을 이해하기 위한 선수 지식

### 2.1 확률분포와 샘플링

- 생성모델은 **데이터의 확률분포 p(x)** 를 학습하고, 그 분포로부터 샘플링하여 데이터를 생성합니다.
- 예: 고양이 이미지들의 분포를 배운 뒤, 고양이 이미지 하나를 생성

### 2.2 노이즈란?

- 노이즈는 **무작위성(randomness)** 을 의미하며, Diffusion Model에서는 이미지에 점진적으로 노이즈를 섞습니다.
- 이 노이즈는 보통 **표준 정규분포**(mean=0, std=1)를 따릅니다.

> 📦 비유: 노이즈는 먼지입니다.  
> 시간이 갈수록 점점 더 먼지가 쌓여 원래 이미지가 보이지 않게 됩니다.

### 2.3 마르코프 과정 (Markov Process)

- 현재 상태가 오직 **이전 상태에만 의존**하는 확률적 과정입니다.
- Diffusion은 마르코프 체인을 따라 **이미지를 노이즈로 변형**합니다.

---

## 3. Diffusion Model의 핵심 개념

### 3.1 Forward Process (Diffusion)

- 데이터를 점차적으로 노이즈로 변형시키는 과정입니다.
- `x_0 → x_1 → x_2 → ... → x_T` 순서로 진행하며, T가 클수록 완전한 노이즈에 가까워집니다.

수식으로 표현하면:

```
q(x_t | x_{t-1}) = 𝒩(x_t; √(1 - β_t) x_{t-1}, β_t I)
```

여기서:
- `β_t`는 timestep t에서 노이즈의 정도를 조절하는 **노이즈 스케줄**
- `𝒩`은 정규분포

> 🧊 비유: 매일 조금씩 얼음을 얹어서 사진을 가려 나가는 것

---

### 3.2 Reverse Process (Denoising)

- Forward의 반대 방향: `x_T → x_{T-1} → ... → x_0`
- 완전히 망가진 노이즈로부터 이미지를 **조금씩 되살려** 갑니다.

실제로는 `p(x_{t-1} | x_t)` 를 모델링합니다.  
하지만 이 확률분포는 알 수 없기 때문에, **딥러닝 모델을 사용하여 근사**합니다.

---

### 3.3 Noise Schedule (β_t)

- 각 timestep마다 노이즈를 얼마나 추가할지를 결정하는 값
- 보통 선형(linear), 코사인(cosine) 형태의 스케줄이 사용됩니다.

> 📈 비유: 처음에는 천천히 더럽히고, 후반에는 빠르게 더럽히는 식의 설계

---

### 3.4 Noise Function ε (Epsilon)

- 모델은 원본 이미지 x₀를 복원하지 않고, **해당 timestep에서의 노이즈(ε)를 예측**합니다.

목표는 다음을 맞추는 것입니다:

```
ε_θ(x_t, t) ≈ ε
```

즉, 모델이 "이 이미지에 어떤 노이즈가 섞였는지"를 맞추는 것이 핵심입니다.

> 🔍 비유: 흐릿한 사진을 보고 “얼마나 먼지가 섞였는지” 추정한 뒤, 먼지를 걷어내는 것

---

## 4. 학습 방식

### 4.1 목표

모델은 **노이즈를 예측하도록 학습**됩니다.  
즉, x_t와 timestep t를 입력받아,  
x_t에 들어있는 **노이즈 ε** 를 맞추는 것이 학습의 목적입니다.

### 4.2 Loss Function

보통 **Mean Squared Error (MSE)** 를 사용합니다:

```
L = E_{t, x₀, ε} [ || ε - ε_θ(x_t, t) ||² ]
```

- 모델이 예측한 노이즈 `ε_θ` 와 실제 노이즈 `ε` 의 차이를 최소화합니다.

---

## 5. 샘플 생성 방법

1. `x_T` (순수 노이즈)에서 시작합니다.
2. 모델이 ε를 예측합니다.
3. ε를 이용해 `x_{T-1}`을 계산합니다.
4. 이 과정을 반복하여 `x_0`에 도달하면 이미지가 완성됩니다.

> 🎲 비유: 진흙으로 뒤덮인 퍼즐을 보고, 한 조각씩 닦아내며 원래 그림을 복원해 나가는 과정입니다.

---

## 6. 주요 모델

### DDPM (Denoising Diffusion Probabilistic Models)

- 가장 기본적인 Diffusion Model 구조
- 느리지만 원리는 단순하고, 품질이 매우 높음

### Stable Diffusion

- Latent 공간에서 Diffusion을 수행하여 **속도와 효율**을 개선
- 텍스트 조건(`Text Prompt`)을 기반으로 이미지 생성 가능
- 텍스트 → 잠재 공간 → 이미지로 이어지는 구조

> 🧠 비유: 실제 이미지를 직접 그리는 게 아니라,  
> 상상의 공간(latent space)에서 그린 뒤 해상도를 높여 출력하는 것

---

## 7. Diffusion Model의 장점과 한계

| 항목 | 설명 |
|------|------|
| 장점 | 매우 고품질, 안정적인 이미지 생성 가능. GAN보다 학습이 안정적임 |
| 단점 | 생성 속도가 느림 (수백~수천 단계 필요), 계산 자원이 많이 듬 |
| 개선 | Latent Diffusion, Fast Sampling 등으로 속도 개선 시도 중 |

---

